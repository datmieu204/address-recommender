# Address Recommender

The project contains two primary components:

| Package                   | Task                                                                                | Model Backbone                                                                            |
| ------------------------- | ----------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- |
| `location_classification` | Sentenceâ€level location classification (does a sentence contain an address?)        | Any ğŸ¤— *transformers* textâ€‘classification model (default: `bert-base-multilingual-cased`) |
| `location_ner`            | Namedâ€‘entity recognition for address components (province, district, ward, streetâ€¦) | Tokenâ€‘classification model (default: `bert-base-multilingual-cased`)                      |

Both subâ€‘packages share a **consistent CLI**, configuration files, and helper utilities to streamline training, evaluation, and inference.

---

## âœ¨ Features

* **Modular codebase** â€“ each concern lives in its own module (`data.py`, `model.py`, `train.py`, â€¦).
* **Zeroâ€‘boilerplate training** â€“ run a single CLI command to fineâ€‘tune or evaluate.
* **Configâ€‘driven** â€“ global hyperâ€‘parameters in `config.py` for easy experimentation.
* **Metrics outâ€‘ofâ€‘theâ€‘box** â€“ accuracy, F1, confusionâ€‘matrix, seqeval scores.
* **Fast prediction API** â€“ import `LocationClassifier` or `LocationNER` and call `.predict()`.
* **Visualization** â€“ utilities to plot confusion matrices and tokenâ€‘level predictions.

---

## ğŸ“‚ Project Structure

```
address-recommender/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ dataset                  # Data crawl and Created Data
â”œâ”€â”€ predict.py               # Highâ€‘level inference helpers
â”œâ”€â”€ location_classification/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py               # Train / evaluate from the command line
â”‚   â”œâ”€â”€ config.py            # Hyperâ€‘parameters & paths
â”‚   â”œâ”€â”€ data.py              # Load & split CSV data
â”‚   â”œâ”€â”€ preprocessing.py     # Tokenisation & Dataset creation
â”‚   â”œâ”€â”€ model.py             # Model factory
â”‚   â”œâ”€â”€ train.py             # Trainer wrapper
â”‚   â”œâ”€â”€ evaluate.py          # Testâ€‘set evaluation
â”‚   â”œâ”€â”€ metrics.py           # compute_metrics() for HuggingÂ Face Trainer
â”‚   â””â”€â”€ visualize.py         # Confusionâ€‘matrix plotting
â””â”€â”€ location_ner/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ cli.py
    â”œâ”€â”€ config.py
    â”œâ”€â”€ data.py              # Read CoNLL format
    â”œâ”€â”€ preprocessing.py
    â”œâ”€â”€ model.py
    â”œâ”€â”€ train.py
    â””â”€â”€ metrics.py
```

---

## ğŸš€ Installation

```bash
# 1. Clone / download the repository
unzip address-recommender.zip && cd address-recommender
or
git clone https://github.com/datmieu204/address-recommender

# 2. Create a virtual environment (optional but recommended)
python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -U pip
pip install transformers datasets seqeval scikit-learn matplotlib
```

---

## ğŸ“‘ Dataset Formats

### 1. Classification

A **CSV** file with at least two columns:

| text                           | label |
| ------------------------------ | ----- |
| "75 Tráº§n HÆ°ng Äáº¡o, Q1, TP.HCM" | 1     |
| "TÃ´i thÃ­ch Äƒn phá»Ÿ."            | 0     |

* **text** â€“ sentence or short paragraph.
* **label** â€“ `1` if the text contains an address, `0` otherwise.

### 2. NER

A **CoNLLâ€‘style** plaintext file (`.txt`, `.conll`, â€¦):

```
75  B-STREET
Tráº§n  I-STREET
HÆ°ng  I-STREET
Äáº¡o  I-STREET
,  O
Q1  B-DISTRICT
,  O
TP.HCM  B-CTY

```

Each line = `token<space>tag`. Sentences separated by a blank line.

---

## ğŸƒâ€â™‚ï¸ Quick Start

### 1. Train a sentenceâ€‘level classifier

```bash
python -m location_classification.cli \
       --csv data/location_sentences.csv \
       --output_dir models/classification
```

### 2. Train an NER model

```bash
python -m location_ner.cli \
       --conll data/location_ner.conll \
       --output_dir models/ner
```

### 3. Evaluate a checkpoint

```bash
python -m location_classification.cli \
       --mode eval \
       --checkpoint_path models/classification/checkpoint-best
```

### 4. Predict in your own script

```python
from address-recommender.predict import LocationClassifier, LocationNER

clf = LocationClassifier(weight_path="models/classification/checkpoint-best")
print(clf("75 Tráº§n HÆ°ng Äáº¡o, Q1, TP.HCM"))  # -> 1

ner = LocationNER(weight_path="models/ner/checkpoint-best")
print(ner("75 Tráº§n HÆ°ng Äáº¡o, Q1, TP.HCM"))
# [('75', 'B-STR'), ('Tráº§n', 'I-STR'), ...]
```

---

## âš™ï¸ Configuration

Every subâ€‘package has a `config.py` with sane defaults:

```python
MODEL_NAME = "bert-base-multilingual-cased"
MAX_LENGTH = 128
BATCH_SIZE = 16
EPOCHS = 3
SEED = 42
```

Override via CLI flags or edit the file directly.

---

## ğŸ“ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.